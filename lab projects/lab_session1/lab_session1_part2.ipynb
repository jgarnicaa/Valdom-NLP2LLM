{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHw-MpQLC382"
      },
      "source": [
        "**All Rights Reserved**\n",
        "\n",
        "**Copyright (c) 2025 IRT Saint-Exupery**\n",
        "\n",
        "*Author & contact:*\n",
        "* mouhcine.mendil@irt-saintexupery.com\n",
        "\n",
        "# Natural Language Processing (NLP) to Large Language Models (LLM)\n",
        "\n",
        "<div align=\"center\">\n",
        "    <h2>Lab Session 1: Part II</h2>\n",
        "</div>\n",
        "\n",
        "## Machine Translation\n",
        "\n",
        "Our task is to automatically translate sentences from English to French. We will not perform a literal word-to-word translation, as the solution is a straighforward word retrieval from a lookup table. Instead, we aim to train the translation model by showing it several examples of English sentences and French sentences.  \n",
        "\n",
        "Machine Translation is an exemple of sequence-to-sequence learning (Seq2Seq), which consists on training models to convert **sequences of variable length** from one domain (e.g. sentences in English) to **sequences of variable length** in another domain (e.g. the same sentences translated to French). This can be used when you need to generate text, such as in machine translation or text summarization. There are multiple ways to handle this task; **We will focus on RNNs** that you have learned previously.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "⚠️⚠️⚠️ Even if seq2seq models are suitable to handle variable-length sequences, they need to be trained on data with similar input sequence length $l_{\\text{input}}$ and output sequence length $l_{\\text{output}}$. We will see how to make this possible later in this notebook. ⚠️⚠️⚠️\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpLLXwlDC384"
      },
      "source": [
        "### 1. English-French MT Dataset\n",
        "\n",
        "We want to train a model to learn English to French translation from a simple dataset hosted in http://www.manythings.org/anki/. Besides, the website provides many translations for other languages such as English, Spanish and Chinese.\n",
        "\n",
        "We have previously download the dataset, which you can find in `data/eng_to_fr.txt`.\n",
        "\n",
        "<div class='alert alert-info'>\n",
        "\n",
        "<b> Exercise 1 </b>\n",
        "\n",
        "- Read in a dataframe the first 20000 rows of the file <code>data/eng_to_fr.txt</code>. Make sure you are using the right separator.\n",
        "- Get a general sense of what the dataset is about and describe it. Is the length of the input and target sequences similar ?\n",
        "- Keep only the first two columns and name them <code>english</code> and <code>french</code>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTqFwrGpC384",
        "outputId": "9fcbbc65-490a-4bda-e06f-fde707699bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 5000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_mt = pd.read_csv(\"https://raw.githubusercontent.com/jgarnicaa/Valdom-NLP2LLM/refs/heads/main/lab%20projects/lab_session1/data/eng_to_fr.txt\", sep=\"\\t\", header=None)\n",
        "df_mt=df_mt.sample(n=5000, random_state=42).reset_index(drop=True)\n",
        "df_mt.drop(2, axis=1, inplace=True)\n",
        "df_mt.columns = [\"english\", \"french\"]\n",
        "print(f\"Number of samples: {len(df_mt)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wHDh2ODqC385",
        "outputId": "b6dde5af-cda1-4318-e840-275c185bb427"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  english  \\\n",
              "0                        Are you envious?   \n",
              "1     All I want you to do is talk to us.   \n",
              "2                  You're a good student.   \n",
              "3                    Can you swim at all?   \n",
              "4          He's curious about everything.   \n",
              "..                                    ...   \n",
              "95  There appears to have been a mistake.   \n",
              "96         He apologized to the employee.   \n",
              "97                           Come off it.   \n",
              "98    Please deposit the money in a bank.   \n",
              "99               Tom came home very late.   \n",
              "\n",
              "                                               french  \n",
              "0                                 Êtes-vous jalouse ?  \n",
              "1   Tout ce que je veux que tu fasses est de nous ...  \n",
              "2                          Vous êtes un bon étudiant.  \n",
              "3                            Sais-tu au moins nager ?  \n",
              "4                             Il est curieux de tout.  \n",
              "..                                                ...  \n",
              "95            Il semble qu'il y ait eu là une erreur.  \n",
              "96                  Il s'excusa auprès de l'employée.  \n",
              "97                                   Arrête ton char.  \n",
              "98  Déposez l'argent dans une banque s'il vous plait.  \n",
              "99                 Tom est rentré chez lui très tard.  \n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad98c6ec-7feb-4824-9e5a-4bc555310f5b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>french</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Are you envious?</td>\n",
              "      <td>Êtes-vous jalouse ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>All I want you to do is talk to us.</td>\n",
              "      <td>Tout ce que je veux que tu fasses est de nous ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You're a good student.</td>\n",
              "      <td>Vous êtes un bon étudiant.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Can you swim at all?</td>\n",
              "      <td>Sais-tu au moins nager ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>He's curious about everything.</td>\n",
              "      <td>Il est curieux de tout.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>There appears to have been a mistake.</td>\n",
              "      <td>Il semble qu'il y ait eu là une erreur.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>He apologized to the employee.</td>\n",
              "      <td>Il s'excusa auprès de l'employée.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Come off it.</td>\n",
              "      <td>Arrête ton char.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Please deposit the money in a bank.</td>\n",
              "      <td>Déposez l'argent dans une banque s'il vous plait.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Tom came home very late.</td>\n",
              "      <td>Tom est rentré chez lui très tard.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad98c6ec-7feb-4824-9e5a-4bc555310f5b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad98c6ec-7feb-4824-9e5a-4bc555310f5b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad98c6ec-7feb-4824-9e5a-4bc555310f5b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_mt",
              "summary": "{\n  \"name\": \"df_mt\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"english\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4937,\n        \"samples\": [\n          \"She glanced through the magazine.\",\n          \"In that case, I'll come.\",\n          \"I don't work for anyone.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"french\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4980,\n        \"samples\": [\n          \"Tu es un tr\\u00e8s bon artiste.\",\n          \"Je ne sais pas laquelle choisir.\",\n          \"Nous \\u00e9tions sur le point d'entrer dans la pi\\u00e8ce.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df_mt.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRjLkZRKC385",
        "outputId": "703065fa-6dc7-4f02-d13f-3c029da06f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   english  5000 non-null   object\n",
            " 1   french   5000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 78.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df_mt.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFO8oWv1C386"
      },
      "source": [
        "### 2. Data Cleaning and preparation\n",
        "<div class='alert alert-info'>\n",
        "<b> Exercise 2.1 </b>\n",
        "\n",
        "- To simplify the problem (smaller vocabulary), lower all capital letters.\n",
        "- Can we apply other data cleaning operations ? Explain your answer.\n",
        "- Split your data into training (80%) and test (20%) subsets using <code>train_test_split</code>, random seed = 42 and <code>shuffle</code> set to True.\n",
        "\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "⚠️⚠️⚠️ Once done, note that vocabulary size and token index will be exclusively based on the train dataset. Make sure you choose the same random seed and other arguments specified in the question. ⚠️⚠️⚠️\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qflEjf0GC386",
        "outputId": "cf80e7b9-16e2-43ba-e4d9-cd6f0954672f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-354221495.py:4: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df_mt_clean = df_mt.applymap(lambda s: s.lower() if type(s) == str else s)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# lower case\n",
        "df_mt_clean = df_mt.applymap(lambda s: s.lower() if type(s) == str else s)\n",
        "\n",
        "# Split data into train and test\n",
        "df_mt_train, df_mt_test = train_test_split(df_mt_clean, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "df_mt_train.reset_index(inplace=True, drop=True)\n",
        "df_mt_test.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cOGG0EnGC386",
        "outputId": "8c5f3557-7c01-4646-c2f1-72beee9a38dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                english  \\\n",
              "0                          can i talk to you for a sec?   \n",
              "1                    i don't know anything about japan.   \n",
              "2     after six games, sampras had the edge on his o...   \n",
              "3                         you should run for president.   \n",
              "4               suddenly, it started to rain very hard.   \n",
              "...                                                 ...   \n",
              "3995            i can't do two things at the same time.   \n",
              "3996                             let's not forget that.   \n",
              "3997               don't worry. i'm not going anywhere.   \n",
              "3998                 i'm not free to go this afternoon.   \n",
              "3999  i just want to let you know that i can't atten...   \n",
              "\n",
              "                                                 french  \n",
              "0                     je peux vous parler une seconde ?  \n",
              "1                          je ne connais rien du japon.  \n",
              "2     après six jeux, sampras prit l'avantage sur so...  \n",
              "3        tu devrais te présenter en tant que président.  \n",
              "4            soudain, il commença à pleuvoir très fort.  \n",
              "...                                                 ...  \n",
              "3995  je ne parviens pas à faire deux choses à la fois.  \n",
              "3996                                ne l'oublions pas !  \n",
              "3997    ne te fais pas de souci. je ne vais nulle part.  \n",
              "3998  je ne suis pas libre de mes mouvements cet apr...  \n",
              "3999  je veux juste te faire savoir que je ne peux p...  \n",
              "\n",
              "[4000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82d3853b-683d-40aa-b660-d65ed6149112\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>french</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>can i talk to you for a sec?</td>\n",
              "      <td>je peux vous parler une seconde ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i don't know anything about japan.</td>\n",
              "      <td>je ne connais rien du japon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>after six games, sampras had the edge on his o...</td>\n",
              "      <td>après six jeux, sampras prit l'avantage sur so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>you should run for president.</td>\n",
              "      <td>tu devrais te présenter en tant que président.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>suddenly, it started to rain very hard.</td>\n",
              "      <td>soudain, il commença à pleuvoir très fort.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>i can't do two things at the same time.</td>\n",
              "      <td>je ne parviens pas à faire deux choses à la fois.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>let's not forget that.</td>\n",
              "      <td>ne l'oublions pas !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>don't worry. i'm not going anywhere.</td>\n",
              "      <td>ne te fais pas de souci. je ne vais nulle part.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>i'm not free to go this afternoon.</td>\n",
              "      <td>je ne suis pas libre de mes mouvements cet apr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>i just want to let you know that i can't atten...</td>\n",
              "      <td>je veux juste te faire savoir que je ne peux p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82d3853b-683d-40aa-b660-d65ed6149112')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82d3853b-683d-40aa-b660-d65ed6149112 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82d3853b-683d-40aa-b660-d65ed6149112');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_348e1baf-760f-4187-8bdf-d5ad752cf9dc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_mt_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_348e1baf-760f-4187-8bdf-d5ad752cf9dc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_mt_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_mt_train",
              "summary": "{\n  \"name\": \"df_mt_train\",\n  \"rows\": 4000,\n  \"fields\": [\n    {\n      \"column\": \"english\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3960,\n        \"samples\": [\n          \"we've got to go.\",\n          \"this railing is not as stable as it could be.\",\n          \"there are seedless grapes and seedless watermelons. i wonder if there are seedless mangoes.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"french\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3991,\n        \"samples\": [\n          \"contacte-moi aussit\\u00f4t que tu arrives ici.\",\n          \"mon v\\u00e9lo n'a rien \\u00e0 voir avec le tien.\",\n          \"j'ai arr\\u00eat\\u00e9 de fumer il y a un an.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_mt_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_xDwf1mC387"
      },
      "source": [
        "To implement Machine Translation, we will rely on sequence-to-sequence (Seq2Seq) models.\n",
        "\n",
        "### Seq2Seq: Encoder/Decoder\n",
        "\n",
        "Seq2Seq has been first introduced by [Google](https://arxiv.org/abs/1409.3215). It captures the information carried by the input sequences in a low-dimensional encoded form and generates relevant output sequences in an iterative manner. Seq2Seq relies on two main blocks: one to read the input sequence (encoder) and another to generate the output sequence (decoder).\n",
        "\n",
        "**Encoder**  \n",
        "The encoder processes the input sequence. It reads the input data **one token at a time** and transform it into a **context vector** (fixed-sized vector), capturing the data's essential information. The encoder (RNN, LSTM, or GRU) traverses the input sequence, updating its internal state at each step. By the end of this process, the internal state of the encoder is a compact representation of the entire input sequence.\n",
        "\n",
        "**Decoder**  \n",
        "The decoder is tasked with generating the output sequence. Starting from the **context vector** produced by the encoder, it generates the output elements one at a time. Like the encoder, the decoder is often implemented as an RNN, LSTM, or GRU. It uses the context vector and what it has generated so far to predict the next element in the output sequence. This process is iterative and continues until a special **end-of-sequence token** is generated (or some other stopping criterion).\n",
        "\n",
        "At each decoding step, the output of the decoder is passed through a **dense layer followed by a softmax function**. The softmax produces a probability distribution over the entire **target vocabulary**, allowing the model to select the most likely next token. This softmax layer is crucial, as it transforms the decoder’s output into a meaningful prediction at every timestep.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/jgarnicaa/Valdom-NLP2LLM/blob/main/lab%20projects/lab_session1/figures/seq2seqmodel.png?raw=1\" width=\"80%\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD8a0QBfC387"
      },
      "source": [
        "----\n",
        "\n",
        "### Tokenization\n",
        "\n",
        "Now we know the type of model we will use, let's move to tokenization. We will rely on character-to-character machine translation; therefore, sentences will be tokenized at <b>character-level</b>.\n",
        "\n",
        "Note however that there are two additional special tokens that we need for Seq2Seq models: the Start-of-Sequence (SOS) token and the End-of-Sequence (EOS).\n",
        "\n",
        "- The SOS is essential for initializing the decoding process. During training, it serves as the first input to the decoder, signaling the model to begin generating the target sequence. This helps the model learn a consistent starting context across all examples. During inference (i.e., when generating a translation), the SOS token is explicitly fed as the first decoder input, which triggers the model to begin producing the output sequence.\n",
        "\n",
        "- The End-of-Sequence (EOS) token, on the other hand, indicates when the generated sequence should stop. It is included in the target output during training so the model can learn to associate certain contexts with the end of a sentence. During inference, the model continues generating tokens until it predicts an EOS token, which signals that the output is complete. Without EOS, the model might continue generating irrelevant tokens or cut off the translation prematurely. Together, SOS and EOS provide clear boundaries for structured and meaningful sequence generation.\n",
        "\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/jgarnicaa/Valdom-NLP2LLM/blob/main/lab%20projects/lab_session1/figures/tokenization.png?raw=1\" width=\"40%\"/>\n",
        "  <figcaption>Author: Shann Khosla<figcaption/>\n",
        "</div>\n",
        "\n",
        "<div class='alert alert-info'>\n",
        "<b> Exercise 2.2 </b>\n",
        "\n",
        "- Add a Start-Of-Sentence (SOS) characters `\\t` and End-Of-Sentence (EOS) character `\\n` to <b>each french sentence (target)</b>. For example, \"bonjour!\" becomes \"\\tbonjour!\\n\"\n",
        "- What is the maximum sequence length for input text (English) and target text (French) ?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8DBnnQkC387",
        "outputId": "9e618140-96ef-4572-fe8d-fcf23ce1b323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max number of characters per text for inputs (English): 164\n",
            "Max number of characters per text for outputs (French): 178\n"
          ]
        }
      ],
      "source": [
        "#Adding SOS and EOS tokens\n",
        "df_mt_train.french = df_mt_train.french.apply(lambda x: '\\t' + x + '\\n')\n",
        "df_mt_test.french = df_mt_test.french.apply(lambda x: '\\t' + x + '\\n')\n",
        "\n",
        "# Max seq lenght for english and french\n",
        "max_fr_seq_len = df_mt_train.french.str.len().max()\n",
        "max_en_seq_len = df_mt_train.english.str.len().max()\n",
        "\n",
        "print(f\"Max number of characters per text for inputs (English): {max_en_seq_len}\")\n",
        "print(f\"Max number of characters per text for outputs (French): {max_fr_seq_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnQjG6OaC388"
      },
      "source": [
        "<div class='alert alert-info'>\n",
        "\n",
        "<b> Exercise 2.3 </b>\n",
        "- Build a vocabulary for the input text (English) and a vocabulary for the target text (French) using only <b>train dataset</b>. What is the size of each vocabulary ?\n",
        "- Build an input token-to-index dictionary to map each character (key) from the previously constructed English vocabulary to a unique index (value).\n",
        "- Build a target token-to-index dictionary to map each character (key) from the previously constructed French vocabulary to a unique index (value).\n",
        "Make sure that the character <code>\\t</code> is associated with index 0 and <code>\\n</code> is associated with index 1.     \n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rad7of6OC388",
        "outputId": "7e5a1a5d-cc80-4625-d80b-e89f95ed7c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of English vocabulary: 46\n",
            "Size of French vocabulary: 68\n"
          ]
        }
      ],
      "source": [
        "# Vocabulary\n",
        "vocab_en = []\n",
        "for text in df_mt_train.english:\n",
        "    for char in text:\n",
        "        if char not in vocab_en:\n",
        "            vocab_en.append(char)\n",
        "vocab_en.sort()\n",
        "vocab_fr = []\n",
        "for text in df_mt_train.french:\n",
        "    for char in text:\n",
        "        if char not in vocab_fr:\n",
        "            vocab_fr.append(char)\n",
        "vocab_fr.sort()\n",
        "print(\"Size of English vocabulary:\", len(vocab_en))\n",
        "print(\"Size of French vocabulary:\", len(vocab_fr))\n",
        "\n",
        "# Token to index lookup dicts for english and french\n",
        "en_token2index_dict = {token: idx for idx, token in enumerate(vocab_en)}\n",
        "fr_token2index_dict = {token: idx for idx, token in enumerate(vocab_fr)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk7d0kB4C389",
        "outputId": "22f564ee-4fd0-4e65-bea0-24fcbacaf182"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "fr_token2index_dict['\\t']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS7ZS0fKC389"
      },
      "source": [
        "### Training vs. Inference in Seq2Seq Models\n",
        "\n",
        "Although the architecture of a Seq2Seq model (encoder + decoder) stays the same, its **behavior during training and inference is very different** — and it’s important to understand why.\n",
        "\n",
        "##### **Training Phase** – *Using the Right Answer*\n",
        "\n",
        "During training, we use a method called **teacher forcing**. This means that at each time step, the decoder is given the **correct previous token** from the target sentence (french) — not the one the model predicted.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/jgarnicaa/Valdom-NLP2LLM/blob/main/lab%20projects/lab_session1/figures/teacher_forcing.png?raw=1\" width=\"40%\"/>\n",
        "  <figcaption>Author: Wanshun Wong<figcaption/>\n",
        "</div>\n",
        "\n",
        "At each step, the model learns to predict the **next token** given the **true previous one**. This makes training faster and more stable because the decoder always knows the \"right context,\" even if it would have made a mistake on its own.\n",
        "\n",
        "**The model is trained to minimize the difference between its predicted output sequence and the true output sequence, using a loss function like cross-entropy.**\n",
        "\n",
        "##### **Inference Phase** – *Using Its Own Predictions*\n",
        "\n",
        "When we switch to inference (i.e., generating a translation), the model doesn’t have access to the ground-truth translation anymore. It has to **generate the output one token at a time**, feeding **its own previous prediction** back into the decoder.\n",
        "\n",
        "It starts with the **start-of-sequence token (SOS)** and continues predicting the next token based on everything it has generated so far. It stops when it outputs the **end-of-sequence token (EOS)** or hits a maximum sequence length.\n",
        "\n",
        "This process is called **autoregressive decoding**, and it's harder because:\n",
        "- There is no ground truth to guide the model\n",
        "- One small error early on can affect all the next predictions\n",
        "\n",
        "##### Summary\n",
        "\n",
        "| Phase     | What is fed to the decoder?          | Purpose                            |\n",
        "|-----------|--------------------------------------|------------------------------------|\n",
        "| Training  | The correct previous token (teacher forcing) | To help the model learn faster and more accurately |\n",
        "| Inference | The model’s own previous prediction  | To test whether the model can generate coherent sequences by itself |\n",
        "\n",
        "Understanding this distinction is key: **teacher forcing helps the model learn**, while **inference checks whether it really has**.\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "Knowing this, let's proceed to the vectorization using one-hot encoding.\n",
        "\n",
        "<div class='alert alert-info'>\n",
        "<b> Exercise 2.4 </b>\n",
        "\n",
        "- Write a function `one_hot_input` that prepares:\n",
        "    - the encoder's inputs `encoder_one_hot_inputs` as a 3D array of shape `(size_corpus, max_english_sentence_length, size_english_vocabulary)` containing the one-hot vectorization of the English sentences. The sentences shorter than `max_english_sentence_length` are to be filled with spaces `\" \"` (padding). Replace out-of-vocabulary tokens by a space `\" \"`.\n",
        "    - the decoder's inputs `decoder_one_hot_inputs` as a 3D array of shape `(size_corpus, max_french_sentence_length, size_french_vocabulary)` containing the one-hot vectorization of the French sentences. The sentences shorter than `max_french_sentence_length` are to be filled with spaces `\" \"`. Replace out-of-vocabulary tokens by a space `\" \"`.\n",
        "</div>\n",
        "\n",
        "Consistently with the teacher forcing approach, notice how the function `one_hot_target` that prepares the decoder's target `decoder_one_hot_targets` is the same as `decoder_one_hot_inputs` but offset by one step: `decoder_one_hot_targets[:, j, :]` $\\leftarrow$ `decoder_one_hot_inputs[:, j + 1, :]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZabZiMfxC389",
        "outputId": "560ff172-0e30-4178-968b-3254ac2e4f38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(df_mt_train.english)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kB3SgwYdC38-"
      },
      "outputs": [],
      "source": [
        "def one_hot_input(corpus, token2index_dict, max_seq_len):\n",
        "    result = np.zeros((len(corpus), max_seq_len, len(token2index_dict)), dtype=\"float32\")\n",
        "    for i, document in enumerate(corpus):\n",
        "        for t, char in enumerate(document):\n",
        "            try:\n",
        "                result[i, t, token2index_dict[char]] = 1\n",
        "                #padding with space if length exceeded\n",
        "            except:\n",
        "                result[i, t, token2index_dict[\" \"]] = 1\n",
        "                continue\n",
        "        result[i, t + 1 :, token2index_dict[\" \"]] = 1.0\n",
        "    return result\n",
        "\n",
        "\n",
        "def one_hot_target(corpus, token2index_dict, max_seq_len):\n",
        "    result = np.zeros(\n",
        "        (len(corpus), max_seq_len, len(token2index_dict)), dtype=\"float32\"\n",
        "    )\n",
        "    for i, document in enumerate(corpus):\n",
        "        for t, char in enumerate(document):\n",
        "            if t > 0:\n",
        "                try:\n",
        "                    result[i, t - 1, token2index_dict[char]] = 1\n",
        "                except:\n",
        "                    result[i, t - 1, token2index_dict[\" \"]] = 1\n",
        "                    continue\n",
        "        result[i, t:, token2index_dict[\" \"]] = 1\n",
        "    return result\n",
        "\n",
        "\n",
        "encoder_one_hot_inputs = one_hot_input(\n",
        "    df_mt_train.english, en_token2index_dict, max_en_seq_len\n",
        ")\n",
        "decoder_one_hot_inputs = one_hot_input(\n",
        "    df_mt_train.french, fr_token2index_dict, max_fr_seq_len\n",
        ")\n",
        "decoder_one_hot_targets = one_hot_target(\n",
        "    df_mt_train.french, fr_token2index_dict, max_fr_seq_len\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjYE4GXpC38-"
      },
      "source": [
        "### 3. Model Training\n",
        "\n",
        "\n",
        "We will now implement the architecture shown in the figure below to train a Seq2Seq model for character-level machine translation.\n",
        "\n",
        "On the left, the encoder processes a sequence of one-hot encoded input characters (from an English sentence) using a stack of GRU cells. As the encoder reads each character, it updates its internal hidden state. Once the final character is processed, the last hidden state becomes the context vector summarizing the entire input sentence.\n",
        "\n",
        "This context vector is then passed to the decoder on the right. The decoder is also composed of GRU cells, and at each time step, it receives:\n",
        "\n",
        "* The one-hot encoded representation of the previous character (from the target sentence during training, or from its own prediction during inference)\n",
        "\n",
        "* The current hidden state (initially, the final hidden state from the encoder)\n",
        "\n",
        "The decoder's GRU outputs are passed through a Dense layer followed by a softmax activation, producing a probability distribution over the target vocabulary at each time step. This allows the model to predict the next character in the output sequence. The decoder continues this autoregressive process until it generates a special end-of-sequence (EOS) token.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/jgarnicaa/Valdom-NLP2LLM/blob/main/lab%20projects/lab_session1/figures/seq2seqmodel.png?raw=1\" width=\"80%\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "<div class='alert alert-info'>\n",
        "<b> Exercise 3.1 </b>\n",
        "\n",
        "- Briefly explain how a GRU layer works: What are its inputs, outputs, and why is it useful in the Seq2Seq context?\n",
        "- Examine and complement the implementation of the `seq2seq_model` function to build the Seq2Seq model.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BZ7H_4o6C38-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def seq2seq_model(latent_dim, input_tokenidx_dict, target_tokenidx_dict):\n",
        "    # Define an input sequence and process it.\n",
        "    input_vocab_size = len(input_tokenidx_dict)\n",
        "    target_vocab_size = len(target_tokenidx_dict)\n",
        "\n",
        "    # 1. Encoder\n",
        "    x_encoder = tf.keras.Input(shape=(None, input_vocab_size))\n",
        "    encoder = tf.keras.layers.GRU(latent_dim, return_state=True)\n",
        "    y_encoder, h_encoder = encoder(x_encoder)\n",
        "\n",
        "    # 2. Decoder\n",
        "    x_decoder = tf.keras.Input(shape=(None, target_vocab_size))\n",
        "    decoder = tf.keras.layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "    y_decoder, _ = decoder(x_decoder, initial_state=h_encoder)\n",
        "\n",
        "    # 3. Output\n",
        "    dense_softmax = tf.keras.layers.Dense(target_vocab_size, activation=\"softmax\")\n",
        "    y_decoder = dense_softmax(y_decoder)\n",
        "\n",
        "    model = tf.keras.Model([x_encoder, x_decoder], y_decoder)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aombBbnYC38_"
      },
      "source": [
        "<div class='alert alert-info'>\n",
        "<b> Exercise 3.2 </b>\n",
        "\n",
        "- Instantiate and train the Seq2Seq model using the teacher forcing approach.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZL5VBO1C39H",
        "outputId": "138acd12-a94b-4c9d-e1c8-68aa3bef15cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.6976 - loss: 2.0416"
          ]
        }
      ],
      "source": [
        "batch_size = 128  # Batch size for training.\n",
        "epochs = 20  # Number of epochs to train for.\n",
        "latent_dim = 512  # dim of the latent space.\n",
        "\n",
        "# Instantiate the model and compile it\n",
        "model = seq2seq_model(latent_dim, en_token2index_dict, fr_token2index_dict)\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Set early stopping if validation accuracy does not improve after `patience` epochs\n",
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=50, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    [encoder_one_hot_inputs, decoder_one_hot_inputs],  # inputs\n",
        "    decoder_one_hot_targets,  # targets\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "YX3ZigwvC39H",
        "outputId": "8130c323-ee6c-46e6-feb7-bfb785b7da92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │    \u001b[38;5;34m860,160\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m893,952\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ gru_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]       │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)  │     \u001b[38;5;34m34,884\u001b[0m │ gru_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">860,160</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">893,952</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]       │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">34,884</span> │ gru_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,577,994\u001b[0m (13.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,577,994</span> (13.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,788,996\u001b[0m (6.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,788,996</span> (6.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,788,998\u001b[0m (6.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,788,998</span> (6.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKgOahffC39I"
      },
      "source": [
        "### 4. Model Inference\n",
        "\n",
        "Unlike training, the target sequence is not known during inference. The model generates the output sequence character by character, starting from an SOS character until it generates an EOS character, signifying the end of the output sequence. Since the true output tokens are not available, the model uses its own predictions as input for the next step. This process is autoregressive and continues until the model produces the EOS or reaches a maximum length.\n",
        "\n",
        "During inference, the model generates the target sequence character by character, in an autoregressive way.\n",
        "\n",
        "<div class='alert alert-info'>\n",
        "<b> Exercise 4.1 </b>\n",
        "\n",
        "- Examine the implementation of the `translate` function and explain how the Seq2Seq model is used for inference.\n",
        "- Run the inference on some test sentences one by one.\n",
        "- What do you notice about errors with this autoregressive generation? Are mistakes equally distributed throughout a sequence (begining, middle and end)?\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yy7UttiaC39I"
      },
      "outputs": [],
      "source": [
        "def translate(input_seq, seq2seq_model=model):\n",
        "    # You can check seq2seq_model.summary() to recall the input and outputs\n",
        "    # of its layers\n",
        "\n",
        "    # Encoder\n",
        "    x_encoder = seq2seq_model.input[0]  # input_1\n",
        "    y_encoder, h_encoder = seq2seq_model.layers[2].output  # lstm_1\n",
        "    encoder = tf.keras.Model(inputs=x_encoder, outputs=h_encoder)\n",
        "\n",
        "    # Decoder\n",
        "    x_decoder = seq2seq_model.input[1]  # input_2\n",
        "    h_in_decoder = tf.keras.Input(shape=(latent_dim,))\n",
        "    gru_layer = seq2seq_model.layers[3]\n",
        "    y_gru, h_out_gru = gru_layer(x_decoder, initial_state=h_in_decoder)\n",
        "    dense_layer = seq2seq_model.layers[4]\n",
        "    y_decoder = dense_layer(y_gru)\n",
        "    decoder_model = tf.keras.Model([x_decoder, h_in_decoder], [y_decoder, h_out_gru])\n",
        "\n",
        "    # Reverse dictionary to recover target vocabulary from token index\n",
        "    token_idx_fr_dict = dict((i, char) for char, i in fr_token2index_dict.items())\n",
        "\n",
        "    def decode_translation(input_seq):\n",
        "        # Encode input as context vector.\n",
        "        h_encoder = encoder.predict(input_seq, verbose=0)\n",
        "\n",
        "        # Generate empty target sequence of length 1.\n",
        "        translated_seq = np.zeros((1, 1, len(fr_token2index_dict)))\n",
        "        # Initialize the first character of target sequence with the SOS.\n",
        "        translated_seq[0, 0, fr_token2index_dict[\"\\t\"]] = 1.0\n",
        "\n",
        "        # Sampling loop for a batch (=1) of sequences\n",
        "        condition = False\n",
        "        decoded_sentence = \"\"\n",
        "        h_in_decoder = h_encoder  # init\n",
        "        while not condition:\n",
        "            y_decoder, h_out_decoder = decoder_model.predict(\n",
        "                [translated_seq, h_in_decoder], verbose=0\n",
        "            )\n",
        "\n",
        "            # Get token\n",
        "            token_index = np.argmax(y_decoder[0, -1, :])\n",
        "            char = token_idx_fr_dict[token_index]\n",
        "            decoded_sentence += char\n",
        "\n",
        "            # Stop condition: find stop character or reach max length\n",
        "            if char == \"\\n\" or len(decoded_sentence) > max_fr_seq_len:\n",
        "                condition = True\n",
        "\n",
        "            # Update the translated sequence.\n",
        "            translated_seq = np.zeros((1, 1, len(fr_token2index_dict)))\n",
        "            translated_seq[0, 0, token_index] = 1.0\n",
        "\n",
        "            # Update hidden state\n",
        "            h_in_decoder = h_out_decoder\n",
        "        return decoded_sentence\n",
        "\n",
        "    return decode_translation(input_seq)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = df_mt_train.english[0:20]\n",
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "O9G7K5ezKGMB",
        "outputId": "c43eaab4-2c75-4ed3-ffed-621feb5e8e9f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                          can i talk to you for a sec?\n",
              "1                    i don't know anything about japan.\n",
              "2     after six games, sampras had the edge on his o...\n",
              "3                         you should run for president.\n",
              "4               suddenly, it started to rain very hard.\n",
              "5                                 glad to see you, tom.\n",
              "6                         when did you finish the work?\n",
              "7                               she is no match for me.\n",
              "8                   i was tired from doing my homework.\n",
              "9                               it's an excellent wine.\n",
              "10                                        come quickly!\n",
              "11                              it's going to be close.\n",
              "12                               don't leave this room.\n",
              "13                         he didn't have a single pen.\n",
              "14                i'm glad to be the one who tells you.\n",
              "15                      you understand this, don't you?\n",
              "16                             tom came home very late.\n",
              "17                          he won the prize last week.\n",
              "18                                   that was horrible.\n",
              "19                     no one in my family can do that.\n",
              "Name: english, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>can i talk to you for a sec?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i don't know anything about japan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>after six games, sampras had the edge on his o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>you should run for president.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>suddenly, it started to rain very hard.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>glad to see you, tom.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>when did you finish the work?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>she is no match for me.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i was tired from doing my homework.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>it's an excellent wine.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>come quickly!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>it's going to be close.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>don't leave this room.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>he didn't have a single pen.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>i'm glad to be the one who tells you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>you understand this, don't you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>tom came home very late.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>he won the prize last week.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>that was horrible.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>no one in my family can do that.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KcI-w0bzC39I",
        "outputId": "7260634f-6b5a-47f5-91d0-b98dd519f6d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------- Sentence 0 --------------------\n",
            "Input sentence: can i talk to you for a sec?\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 1 --------------------\n",
            "Input sentence: i don't know anything about japan.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 2 --------------------\n",
            "Input sentence: after six games, sampras had the edge on his opponent.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 3 --------------------\n",
            "Input sentence: you should run for president.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 4 --------------------\n",
            "Input sentence: suddenly, it started to rain very hard.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 5 --------------------\n",
            "Input sentence: glad to see you, tom.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 6 --------------------\n",
            "Input sentence: when did you finish the work?\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 7 --------------------\n",
            "Input sentence: she is no match for me.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 8 --------------------\n",
            "Input sentence: i was tired from doing my homework.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 9 --------------------\n",
            "Input sentence: it's an excellent wine.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 10 --------------------\n",
            "Input sentence: come quickly!\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 11 --------------------\n",
            "Input sentence: it's going to be close.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 12 --------------------\n",
            "Input sentence: don't leave this room.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 13 --------------------\n",
            "Input sentence: he didn't have a single pen.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 14 --------------------\n",
            "Input sentence: i'm glad to be the one who tells you.\n",
            "Translated sentence: e                                                                                                                                                                                  \n",
            "-------------------- Sentence 15 --------------------\n",
            "Input sentence: you understand this, don't you?\n",
            "Translated sentence: e                                                                                                                                                                                  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1406296217.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# for trying out decoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minput_seq_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_one_hot_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtranslated_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"-------------------- Sentence {i} --------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3699902502.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(input_seq, seq2seq_model)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecode_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3699902502.py\u001b[0m in \u001b[0;36mdecode_translation\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mh_in_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_encoder\u001b[0m  \u001b[0;31m# init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             y_decoder, h_out_decoder = decoder_model.predict(\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mtranslated_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_in_decoder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py\u001b[0m in \u001b[0;36m_enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m             self._flat_output_types)\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# test input sequences\n",
        "\n",
        "for i, seq_index in enumerate(range(20)):\n",
        "\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq_encoded = encoder_one_hot_inputs[seq_index : seq_index + 1]\n",
        "    translated_sentence = translate(input_seq_encoded)\n",
        "\n",
        "    print(f\"-------------------- Sentence {i} --------------------\")\n",
        "    print(\"Input sentence:\", df_mt_train.english[seq_index])\n",
        "    print(\"Translated sentence:\", translated_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srXJ2a6QC39J"
      },
      "source": [
        "BLEU score is one of the most common metrics used to evaluate the quality of machine translation models. It measures how closely the model’s output matches one or more reference translations.\n",
        "\n",
        "<div class='alert alert-info'>\n",
        "<b> Exercise 4.2 </b>\n",
        "\n",
        "* Briefly explain how the BLEU score works. What does it measure, and how is it computed?\n",
        "\n",
        "* Using `nltk.translate.bleu_score`, compute the average BLEU score over at least 100 sentence pairs (predicted vs. reference). Interpret the result: what does it say about the model's performance?\n",
        "\n",
        "* Suggest some ways to improve the performance. For example, you can consider data quality, preparation, vectorization or model architecture.\n",
        "\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}